{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVL7_bgmIAPR"
      },
      "source": [
        "# Unsupervised Learning: Clustering Lab\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6ZbYjZZZ_yLV"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.base import ClusterMixin\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szFqvhK9owBp",
        "outputId": "45bddaea-b82b-4d73-d8f9-9d190d8cbf33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCcEPx5VIORj"
      },
      "source": [
        "## 1. (50%) Implement the k-means clustering algorithm and the HAC (Hierarchical Agglomerative Clustering) algorithm.\n",
        "\n",
        "### 1.1.1 HAC\n",
        "\n",
        "### Code requirements \n",
        "- HAC should support both single link and complete link options.\n",
        "- HAC automatically generates all clusterings from n to 1.  To simplify the amount of output you may want to implement a mechanism to specify for which k values actual output will be generated.\n",
        "\n",
        "\n",
        "---\n",
        "The output should include the following:\n",
        "- The number of clusters (k).\n",
        "- The silhouette score of the full clustering. (You can either write and use your own silhouette_score function (extra credit) or use sklearn's)\n",
        "\n",
        "\n",
        "For each cluster report include:\n",
        "\n",
        "\n",
        "- The centroid id.\n",
        "- The number of instances tied to that centroid. \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_a2KSZ_7AN0G"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance\n",
        "class HACClustering(BaseEstimator,ClusterMixin):\n",
        "\n",
        "    def __init__(self,k=3,link_type='single',dist_type='manhattan'): ## add parameters here\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            k = how many final clusters to have\n",
        "            link_type = single or complete. when combining two clusters use complete link or single link\n",
        "        \"\"\"\n",
        "        self.link_type = link_type\n",
        "        self.k = k\n",
        "        self.dist_type = dist_type\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\" Fit the data; In this lab this will make the K clusters :D\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data\n",
        "            y (array-like): An optional argument. Clustering is usually unsupervised so you don't need labels\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "        \"\"\"\n",
        "        self.clusters = self.init_clusters(X) # 2D python list\n",
        "        # self.dist_mat = self.calc_distance(X) # 2D numpy array\n",
        "        self.dist_mat = distance.cdist(X, X, metric='euclidean') # https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
        "        while  len(self.clusters) > self.k:\n",
        "          nearest_clus_dist = None\n",
        "          clusters_to_combine = None\n",
        "          \n",
        "          for c1 in range(1,len(self.clusters) -2):\n",
        "            for c2 in range(c1+1,len(self.clusters) -1):\n",
        "              # print('self.clusters[c1]:', self.clusters[c1])\n",
        "              # print('self.clusters[c2]:', self.clusters[c2])\n",
        "              dists = self.dist_mat[self.clusters[c1],[c2]]\n",
        "              cur_cluster_dist = None\n",
        "              if self.link_type == 'single':\n",
        "                # print('c1: ', c1)\n",
        "                # print('c2: ', c2)\n",
        "                # print('dist1: ', dist1)\n",
        "                # print('dist2: ', dist2)\n",
        "                cur_cluster_dist = np.min(dists)\n",
        "              else:\n",
        "                cur_cluster_dist = np.max(dists)\n",
        "              if nearest_clus_dist == None or cur_cluster_dist < nearest_clus_dist:\n",
        "                nearest_clus_dist = cur_cluster_dist\n",
        "                clusters_to_combine = [c1,c2]\n",
        "\n",
        "          c1_indx = clusters_to_combine[0]\n",
        "          c2_indx = clusters_to_combine[1]\n",
        "          clusters_to_add = self.clusters[c2_indx]\n",
        "\n",
        "          self.clusters.pop(c2)\n",
        "          self.clusters[c1_indx].extend(clusters_to_add)\n",
        "  \n",
        "        return self\n",
        "\n",
        "    def calc_distance(self,X):\n",
        "      # variable declarations\n",
        "      inst = None\n",
        "      manhat_dists = []\n",
        "      euclid_dists = []\n",
        "      # compute manhattan and euclidean distances\n",
        "      for i in range(X.shape[0]):\n",
        "        inst = X[i]\n",
        "        manhat_dists.append(np.linalg.norm(X - inst, axis=1, ord=1))\n",
        "        euclid_dists.append(np.linalg.norm(X - inst, axis=1))\n",
        "      # return the appropriate distance\n",
        "      if self.dist_type == 'manhattan': \n",
        "        return np.array(manhat_dists) # 2D numpy array\n",
        "      return np.array(euclid_dists) # 2D numpy array\n",
        "\n",
        "    def init_clusters(self,X):\n",
        "      clusters = []\n",
        "      for i in range(X.shape[0]):\n",
        "        clusters.append([i])\n",
        "      return clusters\n",
        "    \n",
        "    def print_clusters(self):\n",
        "        \"\"\"\n",
        "            Used for grading.\n",
        "            print(\"Num clusters: {:d}\\n\".format(k))\n",
        "            print(\"Silhouette score: {:.4f}\\n\\n\".format(silhouette_score))\n",
        "            for each cluster and centroid:\n",
        "                print(np.array2string(centroid,precision=4,separator=\",\"))\n",
        "                print(\"{:d}\\n\".format(size of cluster))\n",
        "        \"\"\"\n",
        "        print(self.clusters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zVaNAfLu6J1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.arange(10)\n",
        "arr = np.reshape(arr,(5,2))\n",
        "print(arr)\n",
        "\n",
        "euclid_dists = []\n",
        "manhat_dists = []\n",
        "for i in range(arr.shape[0]):\n",
        "  inst = arr[i]\n",
        "  # others = list(range(arr.shape[0]))\n",
        "  # others.remove(i)\n",
        "  # others = arr[others,:]\n",
        "  manhat_dists.append(np.linalg.norm(arr - inst, axis=1, ord=1))\n",
        "  euclid_dists.append(np.linalg.norm(arr - inst, axis=1))\n",
        "\n",
        "euclid_dists = np.array(euclid_dists)\n",
        "manhat_dists = np.array(manhat_dists)\n",
        "print('euclid_dists:\\n', euclid_dists)\n",
        "print('manhat_dists:\\n', manhat_dists)\n",
        "rows, cols = np.nonzero(euclid_dists)\n",
        "print(rows)\n",
        "print(cols)\n",
        "print(np.argmin(euclid_dists[rows,cols]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUBvXJDLswz2",
        "outputId": "7369715a-1753-408a-ff58-aab92027c3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1]\n",
            " [2 3]\n",
            " [4 5]\n",
            " [6 7]\n",
            " [8 9]]\n",
            "euclid_dists:\n",
            " [[ 0.          2.82842712  5.65685425  8.48528137 11.3137085 ]\n",
            " [ 2.82842712  0.          2.82842712  5.65685425  8.48528137]\n",
            " [ 5.65685425  2.82842712  0.          2.82842712  5.65685425]\n",
            " [ 8.48528137  5.65685425  2.82842712  0.          2.82842712]\n",
            " [11.3137085   8.48528137  5.65685425  2.82842712  0.        ]]\n",
            "manhat_dists:\n",
            " [[ 0.  4.  8. 12. 16.]\n",
            " [ 4.  0.  4.  8. 12.]\n",
            " [ 8.  4.  0.  4.  8.]\n",
            " [12.  8.  4.  0.  4.]\n",
            " [16. 12.  8.  4.  0.]]\n",
            "[0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4]\n",
            "[1 2 3 4 0 2 3 4 0 1 3 4 0 1 2 4 0 1 2 3]\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = [[0],[1],[2],[3],[4],[5]]\n",
        "array.pop(0)\n",
        "add = [0]\n",
        "array[0].extend(add)\n",
        "print(array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVkWLlac5rEF",
        "outputId": "56d54188-8398-4b12-e68e-d0d2111b2d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 0], [2], [3], [4], [5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KibCIXIThpbE"
      },
      "source": [
        "### 1.1.2 Debug \n",
        "\n",
        "Debug your model by running it on the [Debug Abalone Dataset](https://byu.instructure.com/courses/14142/files?preview=4735805)\n",
        "\n",
        "\n",
        "---\n",
        "The dataset was modified to be a lot smaller. The last datapoint should be on line 359 or the point 0.585,0.46,0.185,0.922,0.3635,0.213,0.285,10. The remaining points should be commented out.\n",
        "\n",
        "\n",
        "- Make sure to include the output class (last column) as an additional input feature\n",
        "- Normalize Data\n",
        "- K = 5\n",
        "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values.\n",
        "\n",
        "\n",
        "---\n",
        "Solutions in files:\n",
        "\n",
        "[Debug HAC Single (Silhouette).txt](https://byu.instructure.com/courses/14142/files?preview=4735819)\n",
        "\n",
        "[Debug HAC Complete (Silhouette).txt](https://byu.instructure.com/courses/14142/files?preview=4735820)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mj1uxSt4oXya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6512364-0a28-4c10-8aae-887885f1c9ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0], [1, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3], [199]]\n"
          ]
        }
      ],
      "source": [
        "# Debug Here\n",
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Load data\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab5_clustering/data/abalone.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "\n",
        "X = np_arr[:,:].astype(float)\n",
        "\n",
        "hac = HACClustering(k=3,link_type='single',dist_type='euclidean')\n",
        "hac.fit(X)\n",
        "\n",
        "hac.print_clusters()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY3VNB1ui03N"
      },
      "source": [
        "### 1.1.3 Evaluation\n",
        "\n",
        "We will evaluate your model based on its print_clusters() output using [Evaluation Seismic-bumps_train Dataset](https://byu.instructure.com/courses/14142/files?preview=4735829)\n",
        "\n",
        "- Make sure to include the output class (last column) as an additional input feature\n",
        "- Normalize Data\n",
        "- K = 5\n",
        "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOQHwSyUoXyb"
      },
      "source": [
        "#### 1.1.3.1 Complete Link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yAxA78QjDh2"
      },
      "outputs": [],
      "source": [
        "# Load evaluation data\n",
        "\n",
        "# Train on evaluation data using complete link\n",
        "\n",
        "# Print clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcFqaW71oXyc"
      },
      "source": [
        "#### 1.1.3.1 Single Link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-5z9ZaxoXyd"
      },
      "outputs": [],
      "source": [
        "# Load evaluation data\n",
        "\n",
        "# Train on evaluation data using single link\n",
        "\n",
        "# Print clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoE_A-DQoXyd"
      },
      "source": [
        "### 1.2.1 K-Means\n",
        "\n",
        "### Code requirements \n",
        "- Ability to choose k and specify k initial centroids\n",
        "- Use Euclidean Distance as metric\n",
        "- Ability to handle distance ties\n",
        "- Include output label as a cluster feature\n",
        "\n",
        "\n",
        "---\n",
        "The output should include the following:\n",
        "- The number of clusters (k).\n",
        "- The silhouette score of the full clustering. (You can either write and use your own silhouette_score function (extra credit) or use sklearn's)\n",
        "\n",
        "\n",
        "For each cluster report include:\n",
        "\n",
        "\n",
        "- The centroid id.\n",
        "- The number of instances tied to that centroid. \n",
        "---\n",
        "You only need to handle continuous features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epXP-YTJoXyd"
      },
      "outputs": [],
      "source": [
        "class KMEANSClustering(BaseEstimator,ClusterMixin):\n",
        "\n",
        "    def __init__(self,k=3,debug=False): ## add parameters here\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            k = how many final clusters to have\n",
        "            debug = if debug is true use the first k instances as the initial centroids otherwise choose random points as the initial centroids.\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.debug = debug\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\" Fit the data; In this lab this will make the K clusters :D\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data\n",
        "            y (array-like): An optional argument. Clustering is usually unsupervised so you don't need labels\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "        \"\"\"\n",
        "        return self\n",
        "    \n",
        "    def print_clusters(self):\n",
        "        \"\"\"\n",
        "            Used for grading.\n",
        "            print(\"Num clusters: {:d}\\n\".format(k))\n",
        "            print(\"Silhouette score: {:.4f}\\n\\n\".format(silhouette_score))\n",
        "            for each cluster and centroid:\n",
        "                print(np.array2string(centroid,precision=4,separator=\",\"))\n",
        "                print(\"{:d}\\n\".format(size of cluster))\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9vxDhLEoXye"
      },
      "source": [
        "### 1.2.2 Debug \n",
        "\n",
        "Debug your model by running it on the [Debug Abalone Dataset](https://byu.instructure.com/courses/14142/files?preview=4735805)\n",
        "\n",
        "\n",
        "- Train until convergence\n",
        "- Make sure to include the output class (last column) as an additional input feature\n",
        "- Normalize Data\n",
        "- K = 5\n",
        "- Use the first k instances as the initial centroids\n",
        "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Solutions in files:\n",
        "\n",
        "[Debug K Means (Silhouette).txt](https://byu.instructure.com/courses/14142/files?preview=4735840)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgAyy82gixIF"
      },
      "outputs": [],
      "source": [
        "# Load debug data\n",
        "\n",
        "# Train on debug data\n",
        "\n",
        "# Print clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iETnFixgoXyf"
      },
      "source": [
        "### 1.2.3 Evaluation\n",
        "\n",
        "We will evaluate your model based on its print_clusters() output using [Evaluation Seismic-bumps_train Dataset](https://byu.instructure.com/courses/14142/files?preview=4735829)\n",
        "- Train until convergence\n",
        "- Make sure to include the output class (last column) as an additional input feature\n",
        "- Normalize Data\n",
        "- K = 5\n",
        "- Use the first k instances as the initial centroids\n",
        "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6FXb9VWoXyf"
      },
      "outputs": [],
      "source": [
        "# Load evaluation data\n",
        "\n",
        "# Train on evaluation data\n",
        "\n",
        "# Print clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWiTdlbR2Xh"
      },
      "source": [
        "## 2.1.1 (7.5%) Clustering the Iris Classification problem - HAC\n",
        "\n",
        "Load the Iris Dataset [Iris Dataset](https://byu.instructure.com/courses/14142/files?preview=4421369)\n",
        "\n",
        "- Use single-link and complete link clustering algorithms\n",
        "- State whether you normalize your data or not (your choice).  \n",
        "- Show your results for clusterings using k = 2-7.  \n",
        "- Graph the silhouette score for each k and discuss your results (i.e. what kind of clusters are being made).\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SSoasDQSKXb"
      },
      "outputs": [],
      "source": [
        "# Iris Classification using single-link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfh0gJvHoXyg"
      },
      "outputs": [],
      "source": [
        "# Iris Classification using complete-link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNr-CNqtoXyg"
      },
      "source": [
        "Discuss differences between single-link and complete-link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-aDaMkmoXyg"
      },
      "source": [
        "## 2.1.2 (5%) Clustering the Iris Classification problem - HAC\n",
        "\n",
        "Requirements:\n",
        "- Repeat excercise 2.1.1 and include the output label as one of the input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0B1gsuPoXyg"
      },
      "outputs": [],
      "source": [
        "# Clustering Labels using single-link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DdaBLR7oXyh"
      },
      "outputs": [],
      "source": [
        "# Clustering Labels using complete-link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-fJS48ioXyh"
      },
      "source": [
        "Discuss any differences between the results from 2.1.1 and 2.1.2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH4dG40EoXyh"
      },
      "source": [
        "## 2.2.1 (7.5%) Clustering the Iris Classification problem: K-Means\n",
        "\n",
        "Load the Iris Dataset [Iris Dataset](https://byu.instructure.com/courses/14142/files?preview=4421369)\n",
        "\n",
        "Run K-Means on the Iris dataset using the output label as a feature and without using the output label as a feature\n",
        "\n",
        "Requirements:\n",
        "- State whether you normalize your data or not (your choice).  \n",
        "- Show your results for clusterings using k = 2-7.  \n",
        "- Graph the silhouette score for each k and discuss your results (i.e. what kind of clusters are being made).\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--8DNFb-oXyh"
      },
      "outputs": [],
      "source": [
        "# Iris Classification without output label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEV6uiMPoXyh"
      },
      "outputs": [],
      "source": [
        "# Iris Classification with output label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKqajObToXyi"
      },
      "source": [
        "Compare results and differences between using the output label and excluding the output label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7J9d3gMoXyi"
      },
      "source": [
        "## 2.2.2 (5%) Clustering the Iris Classification problem: K-Means\n",
        "\n",
        "Requirements:\n",
        "- Use the output label as an input feature\n",
        "- Run K-Means 5 times with k=4, each time with different initial random centroids and discuss any variations in the results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZq6whiroXyi"
      },
      "outputs": [],
      "source": [
        "#K-Means 5 times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcQFpc9QoXyi"
      },
      "source": [
        "Discuss any variations in the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBBmeNQ7jvcQ"
      },
      "source": [
        "## 3.1 (12.5%) Run the SK versions of HAC (both single and complete link) on iris including the output label and compare your results with those above.\n",
        "Use the silhouette score for this iris problem(k = 2-7).  You may write your own code to do silhouette (optional extra credit) or you can use sklearn.metrics.silhouette_score. Please state if you coded your own silhouette score function to receive the extra credit points (described below). Discuss how helpful Silhouette appeared to be for selecting which clustering is best. You do not need to supply full Silhouette graphs, but you could if you wanted to.\n",
        "\n",
        "Requirements\n",
        "- Use the Sillhouette score for this iris problem (k= 2-7) \n",
        "- Use at least one other scoring function from [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) and compare the results. State which metric was used. \n",
        "- Possible sklean metrics include (* metrics require ground truth labels):\n",
        "    - adjusted_mutual_info_score*\n",
        "    - adjusted_rand_score*\n",
        "    - homogeneity_score*\n",
        "    - completeness_score*\n",
        "    - fowlkes_mallows_score*\n",
        "    - calinski_harabasz_score\n",
        "    - davies_bouldin_score\n",
        "- Experiment using different hyper-parameters. Discuss Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFQv70W2VyqJ"
      },
      "outputs": [],
      "source": [
        "# Load sklearn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqSFAXwlk3Ms"
      },
      "source": [
        "*Record impressions*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Eu5-ZkCoXyk"
      },
      "source": [
        "## 3.2 (12.5%) Run the SK version of k-means on iris including the output label and compare your results with those above. \n",
        "\n",
        "Use the silhouette score for this iris problem(k = 2-7). You may write your own code to do silhouette (optional extra credit) or you can use sklearn.metrics.silhouette_score. Please state if you coded your own silhouette score function to receive the extra credit points (described below). Discuss how helpful Silhouette appeared to be for selecting which clustering is best. You do not need to supply full Silhouette graphs, but you could if you wanted to.\n",
        "\n",
        "Requirements\n",
        "- Use the Sillhouette score for this iris problem (k= 2-7) \n",
        "- Use at least one other scoring function form sklearn.metrics and compare the results. State which metric was used\n",
        "- Experiment different hyper-parameters. Discuss Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JGikzJhoXyk"
      },
      "outputs": [],
      "source": [
        "# Load sklearn \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNlij_8CoXyk"
      },
      "source": [
        "*Record impressions*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTlK-kijk8Mg"
      },
      "source": [
        "## 4. (Optional 5% extra credit) For your silhouette experiment above, write and use your own code to calculate the silhouette scores, rather than the SK or other version. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSPFgdY2oXyk"
      },
      "source": [
        "*Show findings here*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYsVb8AcoXyl"
      },
      "outputs": [],
      "source": [
        "# Copy function Below"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab_5_Clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}